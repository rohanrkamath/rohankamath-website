<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Welcome to my world.">
    <meta name="author" content="Rohan Kamath">
    <link rel="shortcut icon" type="image/ico" href="../fav.png" />


    <title>The Blog</title>

    <!-- Bootstrap core CSS -->
    <link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="../vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="../css/clean-blog.min.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-128498707-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-128498707-1');
    </script>

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
        <div class="container">
            <a class="navbar-brand" href="../index.html">The Blog</a>
            <!-- <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../index.html">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../about.html">About</a>
                    </li>
                </ul>
            </div>
        </div> -->
    </nav>

    <!-- Page Header -->
    <header class="masthead" style="background-image: url('../img/blog-2/prop-cover.png')">
        <div class="overlay"></div>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-md-10 mx-auto">
                    <div class="post-heading">
                        <h1>Propaganda? Propaganda.</h1>
                        <h2 class="subheading">My first-ever foray into the research world, on the mission to detect propaganda on Indian Twitter.</h2>
                        <span class="meta">Posted by
              Rohan Kamath
              on July 07, 2021 [8 minutes]</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-md-10 mx-auto">
                    <p>Our research paper <b>"Emotion Enhanced Domain Adaptation for Propaganda Detection in Indian Social Media"</b>
                        has been accepted at the <b>2nd International Conference on Innovations in Computational Intelligence and Computer Vision (ICICV-2021)</b> conference and will be published in the <b>Springer’s book “Advances in Intelligent Systems and Computing”.</b> The conference had an <b>acceptance rate of 13.75%.</b> The paper was
                        also bestowed with the <b>best paper award</b> at the conference. I will update the blog as soon the paper is made available online.</p>

                    <p>
                        In this blog, I will be attempting to explain my research on textual propaganda on social media. For the readers who are just interested in the project, scroll down to the Research section. 
                    </p>
                    <p>Lastly this feat would not be possible without my co-authors Malavikka Rajmohan and Akanksha P. Reddy, under the relentless guidance of Dr. Bhaskarjyoti Das and the support from PES University, Bangalore.</p>
                    <h2 class="section-heading">Introduction</h2>

                    <!-- <h2 class="subsection-heading">What is Propaganda?</h2> -->
                    <p>Shankar is a staunch supporter of the Bharatiya Janata Party (BJP). He whole-heartedly believes BJP is the better party than the other runners. He also calls himself a Modi-Bhakth, truly believing PM Modi's decision making and actions are in the best 
                        interests of the country. So is Shankar a propagandist? No. Could his views be derived from a propagandist, who's sole purpose is to impose their perspective down the public's ideals, and to forment outrage in a community? Possibly. 
                    </p>

                    <img class="img-fluid" src="../img/blog-2/pic1.jpeg" alt="propaganda-banner">
                    <span class="caption text-muted"> Propaganda largely depends on the spread of the "word", rather than just the "word". </span>

                    <p>This is why propaganda is such a devious topic to research upon, as polarity is all about an individual's perspective, hence there could never be a right or a wrong viewpoint. </p>

                    <h2 class="subsection-heading">Fake News, Rumours and Propaganda</h2>
                    <p>Propaganda is often conflated with terms like fake news and rumours. Let us attempt to understand these terms with the following examples.</p>
                    <p>"Rahul married Sunita in Bangalore yesterday", is the word going around the village of Udupi, although Rahul has been married to Roshini since 3 years. Mayank knew about Rahul's marraige, but went on to denigrate his name. Now this is a <b>Fake News.</b> </p>
                    <p>"Rahul married Sunita in Bangalore yesterday", is the word going around the village of Udupi, but this time Mayank does not even know who Rahul is. He just spreads the word for the sake of it, causing a lot of confusion in the village. Now this is a <b>Rumour.</b></p>
                    <p>"Rahul is a hypocrite for divorcing Roshini" is the word going around the village of Udupi. Mayank knows the reason for the divorce, as Roshini was having an affair and Rahul was forced into the divorce. But Mayank is Roshini's good friend, therefore was 
                        going to support her, irrespective for her ill-doings. So he is trying really hard push this perspective of his, onto the gullible villagers. Now this is what is termed <b>Propaganda.</b> </p>
                    <p>
                        So propaganda can be defined as an opinion or specific actions by an individual/group; objective of influencing those of other groups or individuals".
                    </p>

                    <h2 class="subsection-heading">Computational Propaganda</h2>

                    <p>For almost a century, propaganda has existed in many forms. With the progress of science and technology, as well as the growing popularity of social media, propagandists are increasingly using these platforms to sway others with their own views. This is becoming a significant 
                        issue as social media platforms are increasingly being used to nurture a group of individuals rather than serving their intended function. As a result, detecting and eliminating misinformation on social media is critical.</p>
                    <p>
                        With the rise in popularity of social media sites like Twitter, propaganda has become computational.  Propaganda always has an end-goal and in today's environment, propagandists are attempting to reach that aim using computational techniques. ropaganda can have a traceable source
                         and be positive (white), fake news from unreliable sources (black), or anything in between, where source may be recognised but information is incorrect (gray). Disinformation is, in fact, employed as part of a propaganda operation.
                    </p>

                    <h2 class="section-heading">Novelty</h2>

                    <p>
                        There has been handful of research done to detect propaganda, textual and semantics based. But we realised emotions were never considered as factor for propaganda detection, which we thought was imperitive to get more accurate results. Therefore we have employed a transfer learning 
                        method called domain adaptation. Domain adaptation is the ability to apply an algorithm trained in a "source domain" to a different "target domain". We have also incorporated emotions vectors as a dimension into our model.
                    </p>

                    <h2 class="section-heading">Research</h2>
                    <h2 class="subsection-heading">Dataset</h2>
                    <p>
                        <b>Source Dataset -</b> A labelled dataset of news articles from SemEval 2020’s open shared task - Detection of
                        Propaganda in new articles was used.The creators of the task compiled a corpus of about
                        464 news articles in which fragments containing one out of <a href="https://www.uvm.edu/~jleonard/AGRI183/propoaganda.html">18 propaganda techniques</a>
                        were annotated.
                    </p>
                    <p>
                        <b>Target Dataset -</b> A dataset of 597 tweets were scraped on the chosen topic. Based on the background
                        research, 8 highly propagandistic and 2 relatively neutral hashtags were identified. For
                        each hashtag, tweets with appropriate tweet IDs were collected using Twitter APIs. The
                        tweets were then manually annotated with reference to the 18 well documented propaganda techniques, 
                        and after this process, 462 propagandistic and 135 non-propagandistic tweets were collected.
                    </p>

                    <h2 class="subsection-heading">Pre-processing</h2>
                    <p>
                        The model utilises the information from its labelled data at the sentence level to classify
                        the unlabelled data. The following procedures were followed for the source and target:
                    </p>
                    <p>
                        <b>Source Data Preparation -</b> Each sentence of the 464 labelled articles was checked for the presence of a
                        propagandistic span and written into two separate parsed XML files, each containing
                        propagandistic and non-propagandistic sentences respectively.
                    </p>
                    <p>
                        <b>Target Data Preparation -</b> Tweets consist of hashtags, urls, usernames and emojis. The emojis were converted to
                        text and the contents of the hashtags were stored. The 597 manually annotated tweets
                        were then separated out into two files as mentioned above and the remaining unlabelled
                        tweets were written into another file.
                    </p>

                    <h2 class="subsection-heading">Baselines</h2>

                    <p>
                        We worked on three different models, each built on each other. Therefore I will briefly be explaining Baseline 1 and Baseline 2, and expounding on the details of Baseline3.
                    </p>
                    <p>
                        <b>Baseline 1 -</b> The first baseline was a model that identified propagandistic spans in a phrase using a single multilabel token classification head and a 
                        highly adjusted BERT-base uncased model trained on the SEMEVAL dataset. The token classifier is created by adding a linear classification head to BERT's final layer. The BERT model 
                        used had 12 transformer layers with 110 million trained parameters, including batch-size 64, sequence-length 210, early stopping on F1 score on the validation set with a patience value 
                        of 7, 0.01 as weight decay, and Adam optimizer with a learning rate of 3e-5 as hyper-parameters on the validation set. The model was evaluated on unlabeled tweets after being trained for 20 epochs.
                    </p>
                    <p>
                        <b>Baseline 2 -</b> The Pivot Based Language Model (PBLM) is a domain adaptation via representation learning (DRel) approach in which the source and destination learn a structure-aware shared representation.
                         A sequential neural network (LSTM) was employed in the model, which produced a context-dependent vector for each input word. For each tweet, the first phase entailed taking the tagged occurrences and creating 
                         unigram and bigram characteristics. The MI score was then computed, which represented the relevance of a feature to a certain label as a tuple of feature and score. 
                    </p>
                    <p>
                        The second phase included altering the usual 
                         LSTM training method to get the shared representation by only predicting the following word if it was a pivot (as generated from the previous phase). The third step trained the classifier by progressively stacking 
                         the previously trained PBLM model without the softmax layer (containing the structural aware representation) with a CNN and an LSTM, and recording the accuracies of both against the manually annotated tweets.
                    </p>
                    <p>
                        <b>Baseline 3 -</b> The Enhanced PBLM model aims to bring the two baselines together to see the
                        improvement in the performance. This baseline additionally used the emotion footprint as a feature, which was based on Ekman's concept of six fundamental emotions: Anger, Disgust, Fear, Joy, Sadness, and Surprise. 
                        The embedding obtained during the PBLM training phase was multiplied by the relevant emotion vector for each tweet. Matrix multiplication is used to prevent a sparse matrix and to emphasise the emotion signals.
                        For text classification, the resulting vector is input into an LSTM layer and then passed through a dense layer with a sigmoid activation.
                    </p>

                    <img class="img-fluid" src="../img/blog-2/pic2.png" alt="baseline3_diagram">
                    <span class="caption text-muted"> Diagram representation of the workflow of enhanced PBLM (Baseline 3) </span>

                    <p>
                        This is the algorithm we developed for the enhanced PBLM - 
                    </p>

                    <img class="img-fluid" src="../img/blog-2/pic3.png" alt="algorithm">
                    <span class="caption text-muted"> Algorithm of enhanced PBLM </span>

                    <h2 class="section-heading">Results</h2>
                    <br>

                    <img class="img-fluid" src="../img/blog-2/pic4.png" alt="results">
                    <span class="caption text-muted"> Accuracies of the baseline models </span>

                    <p>
                        From the obtained values, we see that transferring features learnt from structured text like
                        news articles does not perform well on a dataset which has a completely different
                        distribution of words, such as in twitter. Thus, baseline 1 does not perform very well on the
                        target dataset having obtained an accuracy of 0.46.
                    </p>
                    <p>
                        From baseline 2, we see that within domain adaptation, PBLM-LSTM classifier performs
                        better than PBLM-CNN by obtaining an accuracy of 0.63 as compared to the latter with
                        0.59 accuracy. Thus, we use the PBLM-LSTM for our enhanced model.
                    </p>
                    <p>
                        Finally, baseline 3 gives an accuracy of 0.75, which proves that adding emotions as a feature can
                        improve the overall performance of a propaganda detection model.
                    </p>

                    <h2 class="section-heading"> Conclusion </h2>
                    <p>
                        Now that we have detected the propaganda, what about the mastermind behind all this, the propagandist? 
                    </p>
                    <p>
                        Our current research is to get to the source, the propagandists who are the main cause of this dissemination, by using social network 
                        analysis (SNA) techniques. We plan on building a retweet graph and use GCN to generate node embeddings and hopefully detect the propagandist.

                    <p></p>

                    <p></p>
                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-md-10 mx-auto">
                    <p class="copyright text-muted">Copyright &copy; Rohan Kamath 2022</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="../vendor/jquery/jquery.min.js"></script>
    <script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="../js/clean-blog.min.js"></script>

</body>

</html>